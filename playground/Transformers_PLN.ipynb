{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo básico basado en Transformers**\n",
        "\n",
        "Con base en Hugging Face - Transformers y Torch, construimos un modelos básico de GPT para completar texto (Generación de texto)."
      ],
      "metadata": {
        "id": "6_xicquwu-6w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Mtx55e2Mu5AU",
        "outputId": "535875e2-7d21-4b4f-ca59-e46ee2df4fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cudnn-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cudnn-cu12\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch\n",
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "#Librerías de trabajo de transformers"
      ],
      "metadata": {
        "id": "7zk3K1-cvnbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt2\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_qxXLz0v8af",
        "outputId": "6697051e-4763-4484-bd07-0afa96333dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_completion(input_text, max_length = 100, num_return_sequences = 1):\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors = \"pt\")\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            input_ids,\n",
        "            max_length = max_length,\n",
        "            num_return_sequences = num_return_sequences,\n",
        "            no_repeat_ngram_size = 2,\n",
        "            top_k = 50,\n",
        "            top_p = 0.95,\n",
        "            temperature = 0.9)\n",
        "        generated_text = []\n",
        "        for i, output in enumerate(output):\n",
        "          text = tokenizer.decode(output, skip_special_tokens = True)\n",
        "          generated_text.append(text)\n",
        "          print(f\"Generated {i + 1}:\\n{text}\\n\")\n",
        "\n",
        "        return generated_text"
      ],
      "metadata": {
        "id": "gKSn8ZwmwT0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Explica detalladamente y solo en español cómo funciona una red neuronal artificial. \"\n",
        "text_completion(input_text, max_length = 200, num_return_sequences = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-FqjqX3yJwE",
        "outputId": "3c98cf2d-91b3-42d6-d9e2-8da6b639cade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 1:\n",
            "Explica detalladamente y solo en español cómo funciona una red neuronal artificial.  \"I am not a scientist, I am a human being. I have no idea what I'm doing. But I do know that I can do something. And I know I will do it. It's not just about me. This is about the world. The world is my home. My home is mine.\n",
            "\"The world has changed. We are all living in a different world now. There is no one to blame but ourselves. Our lives are different now, but we are living together. That is why I want to do this. To make the difference between life and death. If I don't do what is right, then I won't be able to live. So I need to make a difference. Because I believe that if I live, the future will be better for me.\"\n",
            "The following is a transcript of the interview with Dr\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Explica detalladamente y solo en español cómo funciona una red neuronal artificial. \\xa0\"I am not a scientist, I am a human being. I have no idea what I\\'m doing. But I do know that I can do something. And I know I will do it. It\\'s not just about me. This is about the world. The world is my home. My home is mine.\\n\"The world has changed. We are all living in a different world now. There is no one to blame but ourselves. Our lives are different now, but we are living together. That is why I want to do this. To make the difference between life and death. If I don\\'t do what is right, then I won\\'t be able to live. So I need to make a difference. Because I believe that if I live, the future will be better for me.\"\\nThe following is a transcript of the interview with Dr']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_id = \"mrm8488/spanish-gpt3\"\n",
        "\n",
        "# Carga modelo y tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "\n",
        "# Usa CPU o GPU si está disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Prompt claro y enfocado\n",
        "prompt = \"Explica detalladamente y solo en español cómo funciona una red neuronal artificial.\"\n",
        "\n",
        "# Prepara el input\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Generación controlada\n",
        "output = model.generate(\n",
        "    inputs[\"input_ids\"],\n",
        "    max_length=300,\n",
        "    do_sample=False,  # <- esto lo hace más coherente\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Decodifica\n",
        "respuesta = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "print(respuesta)\n",
        "\"\"\"\"Explica detalladamente y solo en español cómo funciona una red neuronal artificial.El sistema de red neuronal artificial es un sistema de red neuronal que se\n",
        "utiliza para conectar a un cerebro con otro.El sistema de red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.\n",
        "La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes:\n",
        " la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.\n",
        " La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes:\n",
        " la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.\n",
        " La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes:\n",
        " la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.\n",
        "La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial\"\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gKYPUn4A7zV",
        "outputId": "7d43f110-b7f9-4ec6-c15e-327b226bb379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explica detalladamente y solo en español cómo funciona una red neuronal artificial.El sistema de red neuronal artificial es un sistema de red neuronal que se utiliza para conectar a un cerebro con otro.El sistema de red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial se compone de dos partes: la red neuronal artificial y la red neuronal artificial.La red neuronal artificial\n"
          ]
        }
      ]
    }
  ]
}