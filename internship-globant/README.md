# Data Engineering Internship - Globant

Welcome to the repository for the projects I developed during my data engineering internship at Globant. This portfolio showcases my practical skills in building automated data pipelines and working with modern data stack technologies.

---

## Projects

### 1. [ETL Pipeline with Medallion Architecture](./etl-medallion-pipeline/README.md)
* **Description:** An end-to-end, containerized ETL pipeline that extracts data from a legacy MySQL database, processes it through Bronze, Silver, and Gold layers using PySpark, and orchestrates the entire workflow with Apache Airflow.
* **Technologies:** Docker, PySpark, MySQL, Airflow, Delta Lake, Parquet.

## Key Skills Demonstrated
* **Data Orchestration:** Apache Airflow
* **Distributed Processing:** Apache Spark (PySpark)
* **ETL/ELT Design:** Medallion Architecture, Data Cleansing, Aggregation
* **Containerization:** Docker & Docker Compose
* **Data Lakehouse:** Delta Lake, Parquet
* **Database Management:** MySQL
