# ğŸš– NYC Taxi: Pipeline de Machine Learning con Polars y Streamlit

Este proyecto implementa un pipeline completo de Machine Learning para predecir la duraciÃ³n de los viajes en taxi de Nueva York. Utiliza **Polars** para el procesamiento de datos de alto rendimiento y **Streamlit** para crear un dashboard interactivo que permite explorar el modelo en tiempo real.

El flujo de trabajo abarca desde el AnÃ¡lisis Exploratorio de Datos (EDA) y la IngenierÃ­a de CaracterÃ­sticas hasta el entrenamiento de un modelo predictivo (LightGBM) y su despliegue en una aplicaciÃ³n web.

## ğŸ“Š Dashboard Interactivo

La aplicaciÃ³n final permite a los usuarios introducir los parÃ¡metros de un viaje y obtener una predicciÃ³n instantÃ¡nea de la duraciÃ³n, ademÃ¡s de visualizar los factores mÃ¡s importantes para el modelo.

![Demo del Dashboard de Streamlit](./stream.png)


## ğŸ¯ Resultados del Modelo Predictivo

El objetivo fue predecir la `trip_duration` (duraciÃ³n del viaje). Se entrenÃ³ un modelo `LGBMRegressor` que logrÃ³ un rendimiento sÃ³lido en el conjunto de prueba.

* **MÃ©trica de EvaluaciÃ³n:** Root Mean Squared Error (RMSE)
* **Resultado:** **4.49 minutos** (Ejemplo, reemplaza con tu valor)

Esto significa que, en promedio, las predicciones del modelo tienen un error de solo ~4.5 minutos, un resultado muy bueno considerando la alta variabilidad del trÃ¡fico en Nueva York.

### Importancia de Features

El anÃ¡lisis del modelo revela quÃ© factores son los mÃ¡s influyentes para realizar una predicciÃ³n:

![GrÃ¡fico de Importancia de Features](./feature_importance.png)

## âš¡ Ventaja de Rendimiento con Polars

Todo el preprocesamiento de datos y la ingenierÃ­a de caracterÃ­sticas se realizaron con **Polars**. Esta elecciÃ³n fue clave para manejar eficientemente el dataset de millones de filas, permitiendo una iteraciÃ³n y experimentaciÃ³n mucho mÃ¡s rÃ¡pidas en comparaciÃ³n con Pandas.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

* **AnÃ¡lisis y Procesamiento:** Polars, Pandas
* **Machine Learning:** Scikit-learn, LightGBM
* **VisualizaciÃ³n:** Matplotlib, Seaborn
* **Dashboard y Despliegue:** Streamlit, Streamlit Cloud
* **Manejo de Modelos:** Joblib

## ğŸ“‚ Estructura del Proyecto

La estructura final del proyecto estÃ¡ organizada para separar la lÃ³gica de la presentaciÃ³n:

```bash
ğŸ“¦ taxi-polars-vs-pandas
 â”£ ğŸ“ data/                   # Dataset parquet (NYC Taxi)
 â”£ ğŸ“ notebooks/              # Notebooks de exploraciÃ³n y prototipos
 â”£ ğŸ“ src/                    # CÃ³digo fuente organizado en mÃ³dulos
 â”ƒ â”£ ğŸ“„ eda.py                # Exploratory Data Analysis
 â”ƒ â”£ ğŸ“„ preprocessing.py      # Limpieza y feature engineering
 â”ƒ â”£ ğŸ“„ training_pipeline.py  # Entrenamiento del modelo
 â”ƒ â”£ ğŸ“„ inference_pipeline.py # Inferencia y predicciones
 â”ƒ â”— ğŸ“„ benchmarking.py       # ComparaciÃ³n Pandas vs Polars
 â”£ ğŸ“ dashboard/              # CÃ³digo para el dashboard en Streamlit
 â”£ ğŸ“„ requirements.txt        # Dependencias del proyecto
 â”— ğŸ“„ README.md               # DocumentaciÃ³n de este proyecto
```

---

## âš¡ Benchmarking Pandas vs Polars

Ejemplo de comparaciÃ³n (lectura + limpieza de 1M registros):

| LibrerÃ­a | Tiempo (s) | Memoria (MB) |
| -------- | ---------- | ------------ |
| Pandas   | 12.5       | 480          |
| Polars   | 4.2        | 210          |

âœ… Polars mostrÃ³ ser **3x mÃ¡s rÃ¡pido** y **2x mÃ¡s eficiente en memoria**.

---

## ğŸ› ï¸ TecnologÃ­as utilizadas

* **Python** ğŸ
* **Pandas** y **Polars**
* **Scikit-learn** para el modelado predictivo
* **Matplotlib / Seaborn / Plotly** para visualizaciÃ³n
* **Streamlit** para el dashboard
* **Docker** (opcional para despliegue reproducible)

---


## ğŸš€ CÃ³mo Ejecutarlo Localmente

1.  **Clonar el repositorio:**
    ```bash
    git clone https://github.com/Parzival099/Intership
    cd Intership
    ```

2.  **Crear un entorno virtual e instalar dependencias:**
    ```bash
    python -m venv venv
    # Activar el entorno (Windows)
    venv\Scripts\activate
    # Activar el entorno (Linux/Mac)
    source venv/bin/activate
    
    pip install -r requirements.txt
    ```

3.  **Entrenar el modelo (solo la primera vez):**
    AsegÃºrate de tener el dataset en la carpeta `data/`. Luego, ejecuta el pipeline de entrenamiento para generar el archivo del modelo.
    ```bash
    python src/training_pipeline.py
    ```

4.  **Ejecutar el dashboard:**
    ```bash
    streamlit run dashboard/app.py
    ```
## â˜ï¸ Despliegue en la nube

El proyecto puede ser desplegado en:

* ğŸŒ **Streamlit Cloud** â†’ simple y rÃ¡pido.
* ğŸ¤— **Hugging Face Spaces** â†’ ideal para modelos ML.
* ğŸš€ **Render / Railway** â†’ despliegue backend + frontend.

---
